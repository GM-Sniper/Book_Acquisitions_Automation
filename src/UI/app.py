import streamlit as st
import sys
import os
import cv2
import time
import tempfile

# Add the project root folder to sys.path
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from src.vision.preprocessing import preprocess_image
from src.vision.OCR_Processing import extract_text_from_image, extract_text_with_confidence
from src.metadata.metadata_extraction import extract_metadata_with_gemini, metadata_combiner
from src.utils.isbn_detection import extract_isbns, extract_and_validate_isbns

# Utility function to save preprocessed image
def save_preprocessed_image(image_np, original_filename, output_dir='data/processed'):
    os.makedirs(output_dir, exist_ok=True)
    base, ext = os.path.splitext(original_filename)
    out_path = os.path.join(output_dir, f"{base}_processed.png")
    cv2.imwrite(out_path, image_np)
    return out_path

# Function to process a single image (works for both camera and file uploads)
def process_image(image_input, image_name, image_type="cover"):
    """Process a single image through the entire pipeline"""
    st.header(f'{image_type.title()} Processing')
    
    # Display original image
    col1, col2 = st.columns(2)
    with col1:
        st.subheader('Original Image')
        st.image(image_input, caption=f'{image_type.title()} (Original)')
    
    # Preprocess and display
    with st.spinner(f'Preprocessing {image_type} with CLAHE enhancement...'):
        # Read image content
        image_content = image_input.read()
        preprocessed_image = preprocess_image(image_content)
    
    with col2:
        st.subheader('Preprocessed Image (CLAHE Enhanced)')
        st.image(preprocessed_image, caption=f'{image_type.title()} (Preprocessed)', channels='GRAY')
    
    # Save preprocessed image
    saved_path = save_preprocessed_image(preprocessed_image, f"{image_name}_{image_type}_{int(time.time())}.jpg")
    st.success(f'âœ… Preprocessed {image_type} saved to: `{saved_path}`')
    
    # OCR with enhanced features
    with st.spinner('Extracting text with confidence scoring...'):
        if use_enhanced_ocr:
            # Use enhanced OCR with confidence
            # Save image temporarily
            with tempfile.NamedTemporaryFile(delete=False, suffix='.jpg') as tmp_file:
                tmp_file.write(image_content)
                tmp_file_path = tmp_file.name
            
            try:
                ocr_result = extract_text_with_confidence(tmp_file_path)
                extracted_text = ocr_result['text']
                confidence = ocr_result['confidence']
                word_count = ocr_result.get('word_count', 0)
            finally:
                # Clean up temporary file
                os.unlink(tmp_file_path)
        else:
            # Use basic OCR
            extracted_text = extract_text_from_image(preprocessed_image)
            confidence = None
            word_count = len(extracted_text.split()) if extracted_text else 0
    
    # Display text extraction results
    st.subheader(f'ğŸ“ Extracted Text ({image_type.title()})')
    st.text_area(f'{image_type.title()} OCR Text', extracted_text, height=150)
    
    if use_enhanced_ocr and confidence is not None:
        # Create confidence indicator
        if confidence >= 0.8:
            confidence_color = "ğŸŸ¢"
            confidence_status = "Excellent"
        elif confidence >= 0.6:
            confidence_color = "ğŸŸ¡"
            confidence_status = "Good"
        elif confidence >= 0.4:
            confidence_color = "ğŸŸ "
            confidence_status = "Fair"
        else:
            confidence_color = "ğŸ”´"
            confidence_status = "Poor"
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Confidence Score", f"{confidence:.2f}", f"{confidence_color} {confidence_status}")
        with col2:
            st.metric("Word Count", word_count)
        with col3:
            st.metric("Text Quality", confidence_status)
    
    return {
        'text': extracted_text,
        'confidence': confidence,
        'word_count': word_count,
        'preprocessed_path': saved_path
    }

# Title of the app
st.title('Enhanced Book Cover OCR System')

# Sidebar for configuration
st.sidebar.header("Configuration")
use_camera = st.sidebar.checkbox("Use Camera Capture (instead of upload)", value=False)
use_enhanced_ocr = st.sidebar.checkbox("Use Enhanced OCR (Confidence Scoring)", value=True)
use_online_validation = st.sidebar.checkbox("Use Online ISBN Validation", value=True)
show_processing_details = st.sidebar.checkbox("Show Processing Details", value=True)

# --- Section: Image Input ---
if use_camera:
    st.header('Step 1: Camera Capture')
    st.write('Use your camera to capture the **front cover** and **back cover** images of the book.')
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Front Cover Capture")
        front_input = st.camera_input("Take a picture of the front cover", key="front_camera")
    
    with col2:
        st.subheader("Back Cover Capture")
        back_input = st.camera_input("Take a picture of the back cover", key="back_camera")

else:
    st.header('Step 1: Upload Book Cover Images')
    st.write('Please upload the **front cover** and **back cover** images of the book.')
    
    col1, col2 = st.columns(2)
    
    with col1:
        front_input = st.file_uploader('Front Cover Image', type=['jpg', 'jpeg', 'png'], key='front')
    
    with col2:
        back_input = st.file_uploader('Back Cover Image', type=['jpg', 'jpeg', 'png'], key='back')

# Check if both images are ready for processing
both_images_ready = front_input is not None and back_input is not None

if front_input and not back_input:
    st.info("ğŸ“· Front cover ready! Please capture/upload the back cover to continue.")
elif back_input and not front_input:
    st.info("ğŸ“· Back cover ready! Please capture/upload the front cover to continue.")
elif not front_input and not back_input:
    st.info("ğŸ“· Please capture/upload both front and back cover images to begin processing.")

# Only process if both images are ready
if both_images_ready:
    st.success("âœ… Both images ready! Starting processing...")
    
    # Process front cover
    front_result = process_image(front_input, "book", "front")
    
    # Process back cover
    back_result = process_image(back_input, "book", "back")
    
    # Extract metadata from front cover
    metadata = None
    if front_result['text']:
        with st.spinner('Extracting metadata with Gemini AI...'):
            metadata = extract_metadata_with_gemini(front_result['text'])
        
        if metadata:
            st.subheader('ğŸ“‹ Extracted Metadata (Front Cover)')
            col1, col2 = st.columns(2)
            with col1:
                if metadata.get('title'):
                    st.success(f"**Title:** {metadata['title']}")
                else:
                    st.warning("**Title:** Not found")
            with col2:
                if metadata.get('authors'):
                    st.success(f"**Authors:** {', '.join(metadata['authors'])}")
                else:
                    st.warning("**Authors:** Not found")
            
            if show_processing_details:
                st.json(metadata)
        else:
            st.warning('âŒ No metadata (title/author) found in front cover text.')
    
    # Extract ISBNs from back cover
    isbns = None
    if back_result['text']:
        with st.spinner('Extracting and validating ISBNs...'):
            if use_online_validation:
                # Use enhanced ISBN detection with online validation
                isbn_results = extract_and_validate_isbns(back_result['text'])
                isbns = isbn_results
            else:
                # Use basic ISBN detection
                isbns = extract_isbns(back_result['text'])
        
        if isbns:
            if use_online_validation:
                st.subheader('ğŸ“š Extracted ISBNs with Online Validation (Back Cover)')
                
                if isbn_results['total_found'] > 0:
                    st.success(f"Found {isbn_results['total_found']} ISBN(s), {isbn_results['validated_count']} validated online")
                    
                    for i, isbn_data in enumerate(isbn_results['isbns']):
                        with st.expander(f"ISBN {i+1}: {isbn_data['isbn']}"):
                            col1, col2 = st.columns(2)
                            with col1:
                                st.write(f"**Original:** {isbn_data['original']}")
                                st.write(f"**Type:** {isbn_data['type']}")
                            with col2:
                                if isbn_data['validation']['valid']:
                                    st.success("âœ… **Validated Online**")
                                    st.write(f"**Title:** {isbn_data['validation']['title']}")
                                    st.write(f"**Authors:** {', '.join(isbn_data['validation']['authors'])}")
                                    st.write(f"**Publisher:** {isbn_data['validation']['publisher']}")
                                else:
                                    st.error("âŒ **Validation Failed**")
                                    st.write(f"**Error:** {isbn_data['validation']['error']}")
                else:
                    st.warning('âŒ No ISBNs found in back cover text.')
            else:
                st.subheader('ğŸ“š Extracted ISBNs (Back Cover)')
                if isbns and (isbns['isbn10'] or isbns['isbn13']):
                    st.json(isbns)
                else:
                    st.warning('âŒ No ISBNs found in back cover text.')
        else:
            st.warning('âŒ No ISBNs found in back cover text.')

    # Combine and display final result if both are available
    if metadata and isbns:
        st.header('ğŸ¯ Final Combined Results')
        
        # Prepare ISBN list for combination
        isbn_list = []
        if use_online_validation and isinstance(isbns, dict) and 'isbns' in isbns:
            # Enhanced ISBN results
            isbn_list = [isbn_data['isbn'] for isbn_data in isbns['isbns']]
        elif isinstance(isbns, dict):
            # Basic ISBN results
            if isbns.get('isbn10'):
                isbn_list.extend(isbns['isbn10'])
            if isbns.get('isbn13'):
                isbn_list.extend(isbns['isbn13'])
        elif isinstance(isbns, list):
            isbn_list = isbns
        
        combined_metadata = metadata_combiner(metadata, isbn_list)
        
        # Display combined results
        col1, col2 = st.columns(2)
        with col1:
            st.subheader("ğŸ“‹ Combined Metadata")
            if combined_metadata.get('title'):
                st.success(f"**Title:** {combined_metadata['title']}")
            if combined_metadata.get('authors'):
                st.success(f"**Authors:** {', '.join(combined_metadata['authors'])}")
            if combined_metadata.get('isbns'):
                st.success(f"**ISBNs:** {', '.join(combined_metadata['isbns'])}")
        
        with col2:
            st.subheader("ğŸ“Š Processing Summary")
            if front_result['confidence']:
                st.metric("Front Cover Confidence", f"{front_result['confidence']:.2f}")
            if back_result['confidence']:
                st.metric("Back Cover Confidence", f"{back_result['confidence']:.2f}")
            if use_online_validation and isinstance(isbns, dict) and 'validated_count' in isbns:
                st.metric("Validated ISBNs", isbns['validated_count'])
        
        if show_processing_details:
            st.subheader("ğŸ” Detailed Results")
            st.json(combined_metadata)

    # Performance metrics
    st.header('ğŸ“ˆ Performance Metrics')
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if front_result['confidence']:
            st.metric("Front Cover Quality", f"{front_result['confidence']:.2f}")
        if back_result['confidence']:
            st.metric("Back Cover Quality", f"{back_result['confidence']:.2f}")
    
    with col2:
        st.metric("Front Words", front_result['word_count'])
        st.metric("Back Words", back_result['word_count'])
    
    with col3:
        if use_online_validation and isinstance(isbns, dict):
            st.metric("ISBNs Found", isbns.get('total_found', 0))
            st.metric("ISBNs Validated", isbns.get('validated_count', 0))

